{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZXbGFu31nkC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HW 2: ML knowledge\n",
        "\n",
        "1. ( 10 pts) Write an expression for expected Loss involving Bias, variance, AND noise, using\n",
        "the concepts of a best function $f^*$, a true joint data distribution on inputs and targets, and a sample of size $N$.\n",
        "2. ( 10 pts) Explain how you might use cross-validation to estimate each of the terms above, and what you\n",
        "might have to assume to make your estimator valid.  Assume you have a very large set of data that you break up into $M$ data sets of size $N$, with $M>>N$, and you have a separate very large test set of size $K>>M$.  \n",
        "\n",
        "3. (10 pts) When we minimize a squared-loss objective for a linear classification problem, data points far away from the boundary have enormous impacts on the solution. The solution is usually considerable undesirable. Does this represent bias, variance, or something else?  Explain in just a few sentences.\n",
        "\n",
        "4. (10 pts) Explain why regularization is needed in machine learning. First explain what problem occurs if you don't regularize, and how this affects the amount of and kinds of data you might need. Then explain what regularization does to help solve the problem, and provide at least two different ways we can regularize our solutions.\n",
        "\n",
        "5. (15 pts) The trade-off in performance in machine learning involves an expectation of a loss.  This involves both the data distribution and the loss.\n",
        "    \n",
        "    a. (5 pts) If we know the data distribution, we can write down the form of the optimal estimator directly in terms of the distribution parameters.  Explain how this works using your results from Homework 1.  \n",
        "\n",
        "    b. (5 pts) If we don't know the data distribution, what can be done?  HINT: How does the hinge loss function in an SVM handle uncertainty in the data distribution?\n",
        "\n",
        "    c. (5 pts) SVMs use convex optimization theory to form a constrained objective that regularizes while penalizing misclassification error.   Which parameters of an SVM affect bias on test data? How does increasing or\n",
        "decreasing these parameters affect bias?\n",
        "\n",
        "\n",
        "6. (30 pts) Understanding optimization.  Machine learning uses optimization to find good solutions.  Under a large range of conditions, this creates a pairing between the parameters of our machine learning and our training data so that our parameters are functions of our training data. This fact is extremely important to keep in mind as it explains many of the complex training requirements in deep learning needed to allow deep learning methods to correctly handle new data. Here we focus on intuition across three viewpoints.\n",
        "    \n",
        "    a. (5 pts) The solutions to least-square regression, logistic regression, generative gaussian models and SVM all take a form where the parameters are explicit functions of the data.  Write down these expressions and write a few sentences explaining the similarities and differences between these solutions.\n",
        "    \n",
        "    b. (5 pts) Consider weight vector for 2-class logistic regression learned by optimizing over a training data $\\mathscr D$: $w_{\\mathscr D} = \\sum_{i \\in \\mathscr D} \\alpha_i x_i + \\alpha_0$ where $\\alpha_i$ are the learned weights.\n",
        "    First, write down an expression for the vector ${\\bf \\alpha}$ by pattern matching off the solution derived in class lecture, so that you recognize the expression above as having the correct form. Hopefully you already did this in your answer to part a.  Next, consider a applying this classifier to a new dataset ${\\bf x_j^{new}} \\in {\\mathscr D}^{new}$ that is statistically similar to the training set _except_ that all the new input points have been translated by a common fixed offset vector ${\\bf v_0}$.  Use this fact to write the test data points in the form ${\\bf x_j^{\\*}} = {\\bf x_j^{new}} - {\\bf v_0}$, and assume that ${\\bf x_j^{*}}$ shares the distribution of the training data.  Answer the following three questions, using the weight formula above to guide your answers: How will classification performance be affected on new data?  How can you fix the problem created by the shift in the new data? Which $\\alpha_i$ parameters might need to be adjusted?\n",
        "    \n",
        "    c. (5 pts) Continuing with the problen in part b, consider the more general transformation ${\\bf x_j^{*}} = {\\bf A}^{-1}{\\bf x_j^{new}} - {\\bf A}^{-1}{\\bf v_0}$ for some fixed, square invertible matrix ${\\bf A}$. Answer the following two questions. One: How does this transformation affect the best solution? (hint: think about what happens if you know both ${\\bf A}$ and ${\\bf v_0}$ and could transform the training data).  Two: Imagine you were to optimize the transformed training data (i.e. re-estimate the $\\alpha_i$ parameters for training data ${\\bf x_j}^{transformed_{train}} = {\\bf A}{\\bf x_j^{train}} + {\\bf A}{\\bf v_0}$.  Show that the solution will be in the form of ${\\bf w}\\_{transformed} = \\sum_{i \\in \\mathscr D} \\alpha_i^{transform} x_i + \\alpha_0^{transform}$, and derive the relationship between ${\\bf \\alpha}^{transform}$ and the non-transformed solution ${\\bf \\alpha}.$ Hint: an explicit expression is possible because the training data points are used to form both solutions.\n",
        "    \n",
        "    d. (10 pts) Continuing with part c, imagine that the training data set included an equal mixture of transformed and untransformed data. Analyze the solution that will result from training on this data by splitting the data into two halves and assume the first half of the data points $i$ = 1:$N/2$ is untransformed and that the second half is transformed with the transformation from part c. Answer the following questions:\n",
        "\n",
        "     i. We know that the solution will take the form of α weighted points.  Will the first half of the weights from the mixture data match the corresponding weights we derived from optimizing over the full untransformed training data?  Argue using the form of the solution for the weights you wrote down in part b.\n",
        "    \n",
        "      ii.  Assume you have separated the two halves of the training data so that you have the transformed and untransformed data in two subsets. Which is the better idea - train a single model on the mixed training data, or train separate models on the two halves and create a mixture of the models?  Note: A mixture of models is a scheme where we allow each model to make separate class predictions and then combine these predictions to form an overall prediction (_termed an ensemble_-- special cases include boosting, bagging and committee machines).  Because we are using logistic regression, make sure you remember that each model produces prediction probabilities: $\\rho_k(x) = p_k(y=1|x,w_{model=k})$.  An emsemble method combines the $\\rho_k$ probabilities that result from the set of $w_{model=k}$ vectors, while the single model produces one $\\rho$ value for a combined $w$ vector.  \n",
        "    \n",
        "     iii. Does the form of the transformation matter?  To guide your answer, consider the following two cases for a 2D feature space $x$.  Case 1, let the best weight vector for the untransformed data be $\\left[ 0, 1, w_0 = 0\\right]$, and the best weight vector for the transformed data be $\\left[ 0.2, 0.8, w_0 = 0.3\\right]$ vs. Case 2,  the untransformed data best is $\\left[ 0, 1, w_0 = 0\\right]$, and the best weight vector for the transformed data is $\\left[ 0, -1, w_0 = 0.0\\right]$.  Use any assumptions you think are needed about the data distributions to form your answer.\n",
        "        \n",
        "    e. Extra Credit (20 pts):  One way to understand why optimization produces solutions that depend on the data is to use the implicit function theorem, and a more sophisticated version uses the ``Envelope Theorem``.  Look at the Wikipedia article on the implicit function theorem. Using the fact that an optimum occurs when the gradient is zero, argue that whenever the implicit function theorem holds, optimization induces an implicit function that sets free parameters in terms of the data.  For full credit, specialize the expression $\\mathrm{d} F = \\operatorname{grad} F \\cdot \\mathrm{d}\\mathbf{r} = \\frac{\\partial F}{\\partial x} \\mathrm{d} x + \\frac{\\partial F}{\\partial y}\\mathrm{d}y$ to a machine learning loss function with parameters and data playing the roles of $x$ and $y$. Use a one-dimensional classifier with a least-squared loss as a concrete example if needed to make the problem easy to solve and understand. Half-credit for just the 1-D argument.  Full credit if you discuss the conditions for the implicit function theorem to hold and express those in terms of ML loss functions parameters and data.\n",
        "\n",
        "\n",
        "7. Imagine we are using 10-fold cross-validation to tune a parameter θ of a machine learning\n",
        "algorithm using training set data for parameter estimation, and using the held-out fold to\n",
        "evaluate test performance of different values of θ. Assume you have a separate data set for testing that is not part of the cross-validation set. This produces 10 models,$\\{ h =  1 ,...,h = 10 \\}$. Each model has its own value $θ_i$ for that parameter, and corresponding average error $e_i$ on the $i^{th}$ training datafold. Let $k= \\arg \\min_i e_i $ be the index of the model with the lowest error. What is the best procedure for going from these 10 individual models to a single model that we can apply to test data?  Articulate assumptions you think you need about the both the training and test data in order to argue which of these alternatives is best:\n",
        "a) Choose model $k$?\n",
        "b) Form an ensemble by weighting the predictions of each model by $w_i= \\exp(−e_i)$?\n",
        "c) Set our machine to $θ = θ_k$, then update it by doing additional training on the held-out data.\n",
        "Clearly explain your choice and reasoning.\n"
      ],
      "metadata": {
        "id": "g2FG3FhK4jYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DIcayBvpK5nn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "snO2LgnYa17R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Gradient Descent (20 pts)\n",
        "\n",
        "Consider the following regularized logistic regression problem:\n",
        "\n",
        "$w^∗= \\text{min}_{w∈R^p} L(w)$\n",
        "\n",
        "where\n",
        "\n",
        "$L(w) = \\frac{1}{n}\\bigl[\\sum\\limits_{i=1}^n -y_iw^tx_i + \\log (1 + \\exp(-w^tx_i))\\bigr]+ \\lambda G(w)$\n",
        "\n",
        "where G(w) is a (possibly non-smooth) regularization function.\n",
        "```\n",
        "1. (5 pts) Derive the subgradient for L(w) if G(w) =\n",
        "```\n",
        "$∑_{i=1}^p(a|w_i|^2+b)^2$\n",
        "```\n",
        "2. (5 pts) Derive a subgradient stochastic gradient descent algorithm for when G(w) =\n",
        "```\n",
        "$∑_{i=1}^p|w_i|$\n",
        "```    \n",
        "3. (5 pts) If G(w) =\n",
        "\n",
        "```\n",
        "$\\frac{1}{2} ∑_{i=1}^p w^2_i$\n",
        ", what is the expected runtimes for Gradient descent\n",
        "and Stochastic Gradient Descent in terms of (n,p)"
      ],
      "metadata": {
        "id": "_Q1eWMXwkDGU"
      }
    }
  ]
}
